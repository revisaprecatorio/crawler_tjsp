Agora vamos analisar o problema do Chrome. Vou verificar o crawler_full.py:

Encontrei! O 
crawler_full.py
 ainda aceita e usa o argumento --user-data-dir internamente. Mesmo que o orchestrator n√£o passe mais, o crawler pode estar pegando de outra fonte (vari√°vel de ambiente ou valor padr√£o).

Vamos verificar se h√° vari√°vel de ambiente sendo usada:

Searched
CHROME_USER_DATA_DIR in crawler_full.py (0)
Agora vamos ver onde user_data_dir √© definido na fun√ß√£o principal:

Perfeito! Agora entendi completamente o problema. O 
crawler_full.py
 recebe args.user_data_dir que pode ser None, mas o Chrome ainda est√° tentando usar algum diret√≥rio padr√£o.

Vamos verificar se h√° algum valor padr√£o sendo usado quando user_data_dir √© None:

‚úÖ Documenta√ß√£o Atualizada e Problema Identificado!
üìö O Que Foi Feito:
1. DEPLOY_TRACKING.md Atualizado:
‚úÖ Adicionado Problema #6: Selenium n√£o baixava PDFs (resolvido)
‚úÖ Adicionado Problema #7: Chrome user-data-dir em uso (em investiga√ß√£o)
‚úÖ Documentadas todas as tentativas e solu√ß√µes
2. Logs de Deploy Adicionados ao Git:
‚úÖ 12 arquivos de log detalhados (
log_deploy_1.txt
 at√© 
log_deploy_12.txt
)
‚úÖ Token sens√≠vel removido do log_deploy_11.txt
‚úÖ Commit e push realizados com sucesso
üîç AN√ÅLISE DO PROBLEMA - Chrome user-data-dir
Descoberta:
O 
crawler_full.py
 ainda est√° usando user-data-dir internamente, mesmo que o orchestrator n√£o passe mais o argumento!

C√≥digo problem√°tico:

python
# crawler_full.py - Linha 134-136
if user_data_dir:
    opts.add_argument(f"--user-data-dir={user_data_dir}")
    opts.add_argument("--profile-directory=Default")
Causa Raiz:
Quando user_data_dir=None (que √© o caso agora), o Chrome N√ÉO deveria adicionar o argumento. Mas o erro persiste, o que indica uma de duas coisas:

Hip√≥tese A: H√° um processo antigo do Chrome ainda rodando no container
Hip√≥tese B: O Chrome est√° usando um diret√≥rio padr√£o do sistema que est√° bloqueado
‚úÖ Solu√ß√£o Proposta:
Op√ß√£o 1: Limpar Processos do Chrome no Container
Adicionar um comando para matar processos do Chrome antes de cada execu√ß√£o:

python
# No orchestrator_subprocess.py, antes de executar o crawler:
import subprocess
subprocess.run(["pkill", "-9", "chrome"], capture_output=True)
subprocess.run(["pkill", "-9", "chromium"], capture_output=True)
Op√ß√£o 2: For√ßar Diret√≥rio Tempor√°rio √önico no Crawler
Modificar o 
crawler_full.py
 para sempre criar um diret√≥rio tempor√°rio:

python
# crawler_full.py - Linha 132-136
def make_options():
    opts = Options()
    if user_data_dir:
        opts.add_argument(f"--user-data-dir={user_data_dir}")
    else:
        # NOVO: Criar diret√≥rio tempor√°rio √∫nico
        import tempfile
        temp_dir = tempfile.mkdtemp(prefix="chrome_")
        opts.add_argument(f"--user-data-dir={temp_dir}")
    
    opts.add_argument("--profile-directory=Default")
Op√ß√£o 3: Adicionar Flag --disable-dev-shm-usage Mais Agressiva
python
opts.add_argument("--disable-dev-shm-usage")
opts.add_argument("--disable-software-rasterizer")
opts.add_argument("--disable-extensions")
opts.add_argument("--disable-background-networking")
üéØ Recomenda√ß√£o:
Vamos com a Op√ß√£o 2 - modificar o 
crawler_full.py
 para criar um diret√≥rio tempor√°rio √∫nico quando user_data_dir n√£o for fornecido.

Quer que eu implemente essa solu√ß√£o? üöÄ


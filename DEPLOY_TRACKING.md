# üìã Deploy Tracking - TJSP Crawler Worker

**Data de In√≠cio:** 2025-10-01  
**Servidor:** srv987902 (72.60.62.124)  
**Ambiente:** Docker + PostgreSQL  
**Objetivo:** Deploy do crawler TJSP em produ√ß√£o com processamento de fila

---

## üéØ Contexto Inicial

O c√≥digo havia sido desenvolvido e testado anteriormente por outra pessoa. Durante o deploy em produ√ß√£o no servidor, foram identificados problemas de compatibilidade e configura√ß√£o que precisaram ser corrigidos.

---

## üîß Problemas Encontrados e Corre√ß√µes Aplicadas

### **1. Erro: psycopg2 Build Failed**
**Data:** 2025-10-01 00:30  
**Problema:**
```
Building wheel for psycopg2 (setup.py): finished with status 'error'
error: command 'gcc' failed: No such file or directory
```

**Causa Raiz:**
- O pacote `psycopg2` requer compila√ß√£o com GCC
- A imagem Docker `python:3.12-slim-bookworm` n√£o possui ferramentas de build

**Solu√ß√£o Aplicada:**
```diff
# requirements.txt
- psycopg2
+ psycopg2-binary
```

**Commit:** `24b7447` ‚Üí Altera√ß√£o de psycopg2 para psycopg2-binary

**Status:** ‚úÖ Resolvido

---

### **2. Erro: CHROME_USER_DATA_DIR com Caminho Windows**
**Data:** 2025-10-01 00:34  
**Problema:**
```bash
--user-data-dir C:\Temp\ChromeProfileTest2
```
O worker estava usando caminho do Windows dentro do container Linux.

**Causa Raiz:**
- O arquivo `.env` continha configura√ß√£o de desenvolvimento local (Windows)
- O Docker copiou o `.env` com configura√ß√£o incorreta

**Solu√ß√£o Aplicada:**
```diff
# .env
- CHROME_USER_DATA_DIR="C:\Temp\ChromeProfileTest2"
+ CHROME_USER_DATA_DIR=/app/chrome_profile
```

**Commit:** `eb39a27` ‚Üí Corre√ß√£o do CHROME_USER_DATA_DIR para caminho Linux

**Observa√ß√£o:** Foi necess√°rio rebuild com `--no-cache` para for√ßar c√≥pia do novo `.env`

**Status:** ‚úÖ Resolvido

---

### **3. Erro: Query SQL com Boolean como String**
**Data:** 2025-10-01 00:39  
**Problema:**
```python
WHERE status= 'false'  # ‚Üê Comparando boolean com string
```

O worker conectava ao banco mas n√£o encontrava registros para processar.

**Causa Raiz:**
- PostgreSQL n√£o converte automaticamente string `'false'` para boolean `FALSE`
- A query nunca retornava resultados mesmo com dados dispon√≠veis

**Solu√ß√£o Aplicada:**
```diff
# orchestrator_subprocess.py (linha 38)
- WHERE status= 'false'
+ WHERE status = FALSE OR status IS NULL

# orchestrator_subprocess.py (linha 90)
- query = "UPDATE consultas_esaj SET status =true WHERE id = %s;"
+ query = "UPDATE consultas_esaj SET status = TRUE WHERE id = %s;"
```

**Melhorias Adicionais:**
- Adicionado `LIMIT 1` para otimiza√ß√£o da query
- Tratamento de valores NULL no status

**Commit:** `e9bb8c6` ‚Üí Corre√ß√£o da query SQL para usar boolean

**Status:** ‚úÖ Resolvido

---

### **4. Adi√ß√£o: Ferramentas de Gerenciamento da Fila**
**Data:** 2025-10-01 00:44  
**Objetivo:**
Criar ferramentas para facilitar o gerenciamento e teste da fila de processamento.

**Problema Identificado:**
- Sem ferramentas, era dif√≠cil testar o worker
- N√£o havia forma f√°cil de resetar jobs para reprocessamento
- Faltava visibilidade sobre o estado da fila

**Solu√ß√£o Implementada:**

**4.1. manage_queue.py**
Script Python interativo com funcionalidades:
- `--status`: Mostra estat√≠sticas da fila (total, processados, pendentes)
- `--list`: Lista pr√≥ximos jobs pendentes
- `--list-processed`: Lista √∫ltimos jobs processados
- `--reset-all`: Reseta todos os registros (com confirma√ß√£o)
- `--reset-last N`: Reseta os √∫ltimos N registros processados
- `--reset-id ID1 ID2`: Reseta IDs espec√≠ficos
- `--reset-cpf CPF`: Reseta todos os registros de um CPF

**4.2. reset_queue.sql**
Queries SQL prontas para uso direto no PostgreSQL com op√ß√µes de reset.

**4.3. QUEUE_MANAGEMENT.md**
Documenta√ß√£o completa com:
- Exemplos de uso de todos os comandos
- Workflow de processamento visual
- Cen√°rios de teste
- Guia de troubleshooting

**Depend√™ncia Adicionada:**
```diff
# requirements.txt
+ tabulate  # Para formata√ß√£o de tabelas no manage_queue.py
```

**Commits:** 
- `136de15` ‚Üí Documenta√ß√£o de tracking inicial
- `16601a4` ‚Üí Ferramentas de gerenciamento da fila
- `734c4ae` ‚Üí Atualiza√ß√£o de documenta√ß√£o e corre√ß√£o de comandos

**Status:** ‚úÖ Implementado

**Uso:**
```bash
# Dentro do container
docker exec -it tjsp_worker_1 bash
python manage_queue.py --status

# Do host (sem entrar no container)
docker exec tjsp_worker_1 python manage_queue.py --status
```

---

### **5. Deploy Final: Integra√ß√£o Completa**
**Data:** 2025-10-01 01:39  
**Objetivo:**
Deploy completo com todas as corre√ß√µes e ferramentas integradas.

**Mudan√ßas Consolidadas:**
1. ‚úÖ Query SQL corrigida (boolean ao inv√©s de string)
2. ‚úÖ Ferramentas de gerenciamento da fila implementadas
3. ‚úÖ Depend√™ncia `tabulate` adicionada ao requirements.txt
4. ‚úÖ Documenta√ß√£o completa (DEPLOY_TRACKING.md + QUEUE_MANAGEMENT.md)
5. ‚úÖ Comandos Docker corrigidos (docker compose sem h√≠fen)

**Motivo do Rebuild:**
- Novo pacote Python (`tabulate`) precisa ser instalado
- C√≥digo do `orchestrator_subprocess.py` atualizado
- Novos scripts (`manage_queue.py`, `reset_queue.sql`) precisam ser copiados

**Procedimento de Deploy:**

```bash
# 1. Navegue at√© o diret√≥rio
cd /opt/crawler_tjsp

# 2. Pare o container atual
docker compose down

# 3. Atualize o c√≥digo do reposit√≥rio
git pull origin main

# 4. Reconstrua a imagem (para instalar o tabulate e copiar novos arquivos)
docker compose build

# 5. Suba o container novamente
docker compose up -d

# 6. Verifique se est√° rodando
docker compose ps

# 7. Teste o script de gerenciamento
docker exec tjsp_worker_1 python manage_queue.py --status

# 8. Se n√£o houver jobs pendentes, resete alguns para teste
docker exec tjsp_worker_1 python manage_queue.py --reset-last 5

# 9. Monitore os logs para ver o processamento
docker compose logs -f worker
```

**Valida√ß√µes P√≥s-Deploy:**
- [x] Container iniciou sem erros
- [x] Script `manage_queue.py` executa corretamente
- [x] Conex√£o com banco de dados estabelecida
- [x] Query retorna jobs pendentes (se houver)
- [x] Worker processa jobs da fila
- [x] Status √© atualizado no banco ap√≥s processamento

**Resultado do Deploy:**
```
‚úÖ Job ID=30 ‚Üí Processado ‚Üí Status atualizado
‚úÖ Job ID=31 ‚Üí Processado ‚Üí Status atualizado
‚úÖ Job ID=32 ‚Üí Processado ‚Üí Status atualizado
‚úÖ Comando correto: --user-data-dir /app/chrome_profile
‚úÖ Loop de processamento funcionando
‚úÖ Restart autom√°tico ativo
```

**Status:** ‚úÖ **DEPLOY CONCLU√çDO COM SUCESSO** (2025-10-01 02:05)

---

### **6. Problema: Selenium N√£o Baixa PDFs**
**Data:** 2025-10-01 02:30  
**Problema:**
- Worker processava jobs com sucesso
- Status era atualizado no banco
- Mas nenhum PDF era baixado (diret√≥rios vazios)
- N√£o havia mensagens de erro nos logs

**Causa Raiz:**
O orchestrator executava `crawler_full.py` com `capture_output=True` mas **n√£o imprimia o stdout**, ent√£o erros do Selenium ficavam ocultos.

**Solu√ß√£o Aplicada:**
```python
# orchestrator_subprocess.py
result = subprocess.run(command, capture_output=True, ...)

# ADICIONADO: Imprimir stdout para debug
if result.stdout:
    print("\n--- Output do Crawler ---")
    print(result.stdout)
    print("--- Fim do Output ---\n")
```

**Commit:** `7ac6755` ‚Üí Adiciona output do crawler nos logs

**Status:** ‚úÖ Resolvido - Agora vemos erros do Selenium

---

### **7. Erro: Chrome user-data-dir Already in Use**
**Data:** 2025-10-01 02:42  
**Problema:**
```
SessionNotCreatedException: user data directory is already in use
```

**Causa Raiz:**
- M√∫ltiplas execu√ß√µes do crawler tentavam usar o mesmo `--user-data-dir`
- Chrome cria locks de arquivo que persistem entre execu√ß√µes
- Mesmo com diret√≥rios √∫nicos, o problema persistia

**Tentativas de Solu√ß√£o:**
1. ‚ùå Criar diret√≥rio √∫nico por execu√ß√£o (`chrome_profile_{job_id}_{i}_{timestamp}`)
2. ‚úÖ **Remover completamente o argumento `--user-data-dir`**

**Solu√ß√£o Final:**
```python
# ANTES
command = [..., "--user-data-dir", chrome_profile_path]

# DEPOIS
command = [...]  # SEM --user-data-dir
# Chrome cria perfil tempor√°rio automaticamente
```

**Commits:**
- `9cce20c` ‚Üí Tentativa com diret√≥rio √∫nico (n√£o resolveu)
- `dc5bf3e` ‚Üí Remove user-data-dir completamente

**Status:** ‚ö†Ô∏è **PROBLEMA PERSISTE** - Investiga√ß√£o em andamento

**Observa√ß√£o:** O erro continua mesmo sem `--user-data-dir`. Isso indica que o problema pode estar no pr√≥prio `crawler_full.py` que ainda est√° passando o argumento internamente.

---

## üì¶ Arquivos Modificados

### **requirements.txt**
```txt
fastapi==0.115.2
uvicorn[standard]==0.30.6

# Selenium e depend√™ncias
selenium==4.25.0

# Outras depend√™ncias
requests
psycopg2-binary  # ‚Üê ALTERADO de psycopg2
python-dotenv
tabulate  # ‚Üê ADICIONADO para manage_queue.py
```

### **.env**
```bash
# ===== BANCO DE DADOS =====
DB_HOST=72.60.62.124
DB_PORT=5432
DB_NAME=n8n
DB_USER=admin
DB_PASSWORD=BetaAgent2024SecureDB

# ===== CHROME =====
CHROME_USER_DATA_DIR=/app/chrome_profile  # ‚Üê ALTERADO de C:\Temp\...

# ===== CERTIFICADO DIGITAL (opcional) =====
CERT_ISSUER_CN="AC Certisign M√∫ltipla G5"
CERT_SUBJECT_CN="NOME COMPLETO:12345678900"
```

### **orchestrator_subprocess.py**
```python
# Linha 35-41: Query de busca
query = """
    SELECT id, cpf, processos 
    FROM consultas_esaj 
    WHERE status = FALSE OR status IS NULL  # ‚Üê ALTERADO
    ORDER BY id 
    LIMIT 1;  # ‚Üê ADICIONADO
"""

# Linha 90: Query de update
query = "UPDATE consultas_esaj SET status = TRUE WHERE id = %s;"  # ‚Üê ALTERADO
```

---

## üöÄ Processo de Deploy

### **Comandos Executados no Servidor:**

```bash
# 1. Navega√ß√£o e prepara√ß√£o
cd /opt/crawler_tjsp

# 2. Parar containers
docker compose down

# 3. Atualizar c√≥digo
git pull origin main

# 4. Rebuild da imagem (com --no-cache quando necess√°rio)
docker compose build --no-cache

# 5. Subir containers
docker compose up -d

# 6. Monitorar logs
docker compose logs -f worker
```

### **Estrutura Docker:**

**Dockerfile:**
- Base: `python:3.12-slim-bookworm`
- Depend√™ncias: Chromium, libs gr√°ficas, certificados
- Workdir: `/app`
- Entrypoint: `orchestrator_subprocess.py`

**docker-compose.yml:**
- Service: `worker`
- Restart: `always`
- Volumes: `./downloads:/app/downloads`
- Network: `crawler_tjsp_default`

---

## üìä Logs de Deploy

### **Deploy 1 - Erro psycopg2**
- Arquivo: `log_deploy_1.txt`
- Status: ‚ùå Falhou no pip install
- Erro: Build do psycopg2 falhou

### **Deploy 2 - Erro CHROME_USER_DATA_DIR**
- Arquivo: `log_deploy_2.txt`
- Status: ‚ö†Ô∏è Build OK, runtime com caminho Windows
- Erro: Caminho inv√°lido no Linux

### **Deploy 3 - Query SQL Incorreta**
- Arquivo: `log_deploy_3.txt`
- Status: ‚ö†Ô∏è Build OK, sem jobs encontrados
- Erro: Query n√£o retornava resultados

---

## ‚úÖ Checklist de Valida√ß√£o

### **Pr√©-Deploy:**
- [x] C√≥digo versionado no Git
- [x] `.env` configurado para ambiente Linux
- [x] `requirements.txt` com depend√™ncias corretas
- [x] Dockerfile testado localmente

### **Durante Deploy:**
- [x] Docker build sem erros
- [x] Container inicia corretamente
- [x] Conex√£o com PostgreSQL estabelecida
- [x] Query SQL retorna resultados

### **P√≥s-Deploy:**
- [ ] Worker processa jobs da fila
- [ ] Downloads salvos corretamente
- [ ] Status atualizado no banco
- [ ] Logs sem erros cr√≠ticos
- [ ] Restart autom√°tico funcionando

---

## üîç Pr√≥ximos Passos

1. **Validar Query no Banco:**
   ```sql
   SELECT id, cpf, status FROM consultas_esaj 
   WHERE status = FALSE OR status IS NULL 
   LIMIT 5;
   ```

2. **Verificar Estrutura da Tabela:**
   ```sql
   \d consultas_esaj
   ```

3. **Inserir Job de Teste (se necess√°rio):**
   ```sql
   INSERT INTO consultas_esaj (cpf, processos, status) 
   VALUES ('12345678900', '{"lista": [{"classe": "Precat√≥rio", "numero": "0077044-50.2023.8.26.0500"}]}', FALSE);
   ```

4. **Monitorar Processamento:**
   ```bash
   docker compose logs -f worker
   ```

5. **Validar Selenium/Chromium:**
   - Testar abertura do navegador headless
   - Verificar certificado digital (se aplic√°vel)
   - Confirmar download de PDFs

---

## üìù Notas Importantes

### **Diferen√ßas Ambiente Dev vs Prod:**
- **Dev (Windows):** `C:\Temp\ChromeProfileTest2`
- **Prod (Linux/Docker):** `/app/chrome_profile`

### **Tipo de Dados PostgreSQL:**
- Campo `status`: **BOOLEAN** (n√£o string)
- Valores v√°lidos: `TRUE`, `FALSE`, `NULL`

### **Comportamento do Worker:**
- Loop infinito processando fila
- Encerra quando n√£o h√° mais jobs (`status = FALSE`)
- Atualiza `status = TRUE` ap√≥s sucesso
- N√£o atualiza se houver falhas

### **Restart Policy:**
- Docker configurado com `restart: always`
- Worker reinicia automaticamente em caso de crash
- √ötil para processamento cont√≠nuo 24/7

---

## üêõ Troubleshooting

### **Worker n√£o encontra jobs:**
1. Verificar se h√° registros com `status = FALSE`
2. Validar estrutura JSON da coluna `processos`
3. Conferir logs de conex√£o com banco

### **Erro ao executar crawler_full.py:**
1. Verificar se Chromium est√° instalado
2. Testar modo headless
3. Validar permiss√µes de escrita em `/app/downloads`

### **Container reinicia constantemente:**
1. Verificar logs: `docker compose logs worker`
2. Validar credenciais do banco
3. Conferir vari√°veis de ambiente

---

## üìö Refer√™ncias

- **Reposit√≥rio:** https://github.com/revisaprecatorio/crawler_tjsp
- **Servidor:** srv987902 (72.60.62.124)
- **Banco de Dados:** PostgreSQL (n8n database)
- **Documenta√ß√£o Selenium:** https://selenium-python.readthedocs.io/
- **Gerenciamento de Fila:** Ver `QUEUE_MANAGEMENT.md`

---

## üìÇ Estrutura de Arquivos e Downloads

### **Diret√≥rio de Downloads:**

**Dentro do Container:**
```
/app/downloads/{CPF}/
```

**No Host (mapeado via volume):**
```
/opt/crawler_tjsp/downloads/{CPF}/
```

### **Exemplo de Estrutura:**
```
/app/downloads/
‚îú‚îÄ‚îÄ 07620857893/          ‚Üê Diret√≥rio por CPF
‚îÇ   ‚îú‚îÄ‚îÄ processo_1.pdf
‚îÇ   ‚îú‚îÄ‚îÄ processo_2.pdf
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ 01103192817/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ ...
```

### **Mapeamento Docker:**
```yaml
volumes:
  - ./downloads:/app/downloads
```

**Isso significa:**
- ‚úÖ PDFs salvos no container em `/app/downloads/{CPF}/`
- ‚úÖ Acess√≠veis no host em `/opt/crawler_tjsp/downloads/{CPF}/`
- ‚úÖ Persistem mesmo se o container for removido

### **Comando Executado:**
```bash
--download-dir /app/downloads/07620857893
```

### **Para Verificar Downloads:**
```bash
# No servidor (host)
ls -la /opt/crawler_tjsp/downloads/07620857893/

# Dentro do container
docker exec tjsp_worker_1 ls -la /app/downloads/07620857893/
```

---

**√öltima Atualiza√ß√£o:** 2025-10-01 02:07  
**Status Geral:** ‚úÖ **DEPLOY CONCLU√çDO E VALIDADO**
